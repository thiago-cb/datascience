{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Predicting House Sale Prices\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this project, we'll work with housing data for the city of Ames, Iowa, United States from 2006 to 2010. Information about the data collection can be found [here](https://doi.org/10.1080/10691898.2011.11889627), and information about the different columns in the data [here](http://jse.amstat.org/v19n3/decock/DataDocumentation.txt).\n",
    "\n",
    "Let's start by setting up a pipeline of functions that will let us quickly iterate on different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the libraries\n",
    "import pandas as pd\n",
    "pd.options.display.max_columns = 999 # to avoid displaying truncated output\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read in the data as DataFrame\n",
    "df = pd.read_csv('AmesHousing.tsv', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_features(df):\n",
    "    return df\n",
    "\n",
    "def select_features(df):\n",
    "    return df[['Gr Liv Area', 'SalePrice']]\n",
    "\n",
    "def train_and_test(df):\n",
    "    train = df[0:1460]\n",
    "    test = df[1460:]\n",
    "    \n",
    "    # Select only numerical columns\n",
    "    numeric_train = train.select_dtypes(include=['int', 'float'])\n",
    "    numeric_test = test.select_dtypes(include=['int', 'float'])\n",
    "    \n",
    "    # Assign features and target columns\n",
    "    features = numeric_train.columns.drop('SalePrice')\n",
    "    target = 'SalePrice'\n",
    "    \n",
    "    lr = LinearRegression()\n",
    "    lr.fit(train[features], train[target])\n",
    "    predictions = lr.predict(test[features])\n",
    "    \n",
    "    mse = mean_squared_error(test[target], predictions)\n",
    "    rmse = np.sqrt(mse)\n",
    "    \n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57088.25161263909"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run our initial functions\n",
    "transformed_df = transform_features(df)\n",
    "filtered_df = select_features(transformed_df)\n",
    "rmse = train_and_test(filtered_df)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "Let's now start removing features with many missing values, diving deeper into potential categorical features, and transforming text and numerical columns.\n",
    "\n",
    "We'll handle missing values as follows:\n",
    "\n",
    "1. `All columns`: Drop any with 5% or more missing values **for now**.\n",
    "2. `Text columns`: Drop any with 1 or more missing values **for now**.\n",
    "3. `Numerical columns`: Fill in the missing values using the most popular value for that column.\n",
    "\n",
    "**Step 1:** Drop `all columns` with 5% or more missing values **for now**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Total number of missing values for each column\n",
    "all_mv_counts = df.isnull().sum()\n",
    "\n",
    "# Columns containing >5% missing values\n",
    "drop_missing_cols = all_mv_counts[all_mv_counts > len(df)*0.05]\n",
    "\n",
    "# Drop those columns from the df DataFrame\n",
    "df = df.drop(drop_missing_cols.index, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2:** Drop any `text column` with 1 or more missing values **for now**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of missing values for text columns\n",
    "text_mv_counts = df.select_dtypes(include=['object']).isnull().sum()\n",
    "\n",
    "# Text columns containing any missing values\n",
    "drop_missing_cols_2 = text_mv_counts[text_mv_counts > 0]\n",
    "\n",
    "# Drop those columns from the df DataFrame\n",
    "df = df.drop(drop_missing_cols_2.index, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3:** Fill in the missing values in the `numerical columns` using the most popular value for that column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of missing values for numerical columns\n",
    "numeric_mv_counts = df.select_dtypes(include=['int', 'float']).isnull().sum()\n",
    "\n",
    "# Numerical columns containing any missing values\n",
    "fixable_numeric_cols = numeric_mv_counts[numeric_mv_counts > 0]\n",
    "\n",
    "# Fill in 'NaN' values with the most common value for each numerical column\n",
    "df = df.fillna(df[fixable_numeric_cols.index].mode().iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    64\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that every column has 0 missing values\n",
    "df.isnull().sum().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns `Year Built` and `Year Remod/Add` represent the year of construction and the year of remodelling, respectively.\n",
    "\n",
    "\n",
    "We'll use these columns to create new features to show how many years have passed since the construction and remodelling.\n",
    "The data of these two new columns should be *positive* values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2180   -1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "years_sold = df['Yr Sold'] - df['Year Built']\n",
    "years_sold[years_sold < 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1702   -1\n",
       "2180   -2\n",
       "2181   -1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "years_since_remod = df['Yr Sold'] - df['Year Remod/Add']\n",
    "years_since_remod[years_since_remod < 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create the new features and drop the rows with negative values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create new columns\n",
    "df['Years Before Sale'] = years_sold\n",
    "df['Years Since Remod'] = years_since_remod\n",
    "\n",
    "# Drop rows with negative values for both these new columns\n",
    "df = df.drop([1702, 2180, 2181], axis=0)\n",
    "\n",
    "# Drop the columns used to create the new columns. No longer need them.\n",
    "df = df.drop(['Year Built', 'Year Remod/Add'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also remove columns that aren't useful for *Machine Learning*, and columns that leak data about the final sale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop columns that aren't useful for ML\n",
    "df = df.drop(['PID', 'Order'], axis=1)\n",
    "\n",
    "# Drop columns that leak info about the final sale\n",
    "df = df.drop(['Mo Sold', 'Sale Condition', 'Sale Type', 'Yr Sold'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's update `transform_features()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_features(df):\n",
    "    \n",
    "    # Drop any column with 5% or more missing values\n",
    "    all_mv_counts = df.isnull().sum()\n",
    "    drop_missing_cols = all_mv_counts[all_mv_counts > len(df)*0.05]\n",
    "    df = df.drop(drop_missing_cols.index, axis=1)\n",
    "    \n",
    "    # Drop any text columns with 1 or more missing values\n",
    "    text_mv_counts = df.select_dtypes(include=['object']).isnull().sum()\n",
    "    drop_missing_cols_2 = text_mv_counts[text_mv_counts > 0]\n",
    "    df = df.drop(drop_missing_cols_2.index, axis=1)\n",
    "    \n",
    "    # Fill in 'NaN' values with the most common value for each numerical column\n",
    "    numeric_mv_counts = df.select_dtypes(include=['int', 'float']).isnull().sum()\n",
    "    fixable_numeric_cols = numeric_mv_counts[numeric_mv_counts > 0]\n",
    "    df = df.fillna(df[fixable_numeric_cols.index].mode().iloc[0])\n",
    "    \n",
    "    # Create new features and drop rows with negative values for both columns\n",
    "    df['Years Before Sale'] = df['Yr Sold'] - df['Year Built']\n",
    "    df['Years Since Remod'] = df['Yr Sold'] - df['Year Remod/Add']\n",
    "    df = df.drop([1702, 2180, 2181], axis=0)\n",
    "    \n",
    "    # Drop columns no longer needed, not useful for ML or that leak info about the final sale\n",
    "    df = df.drop(['PID', 'Order', 'Mo Sold', 'Sale Condition', 'Sale Type', 'Year Built', 'Year Remod/Add'], axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55275.36731241307"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run our functions after updating 'transform_features' function\n",
    "df = pd.read_csv(\"AmesHousing.tsv\", delimiter=\"\\t\")\n",
    "\n",
    "transformed_df = transform_features(df)\n",
    "filtered_df = select_features(transformed_df)\n",
    "rmse = train_and_test(filtered_df)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "\n",
    "Now that we have cleaned and transformed a lot of the features in the dataset, we'll move on to feature selection for numerical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MS SubClass</th>\n",
       "      <th>Lot Area</th>\n",
       "      <th>Overall Qual</th>\n",
       "      <th>Overall Cond</th>\n",
       "      <th>Mas Vnr Area</th>\n",
       "      <th>BsmtFin SF 1</th>\n",
       "      <th>BsmtFin SF 2</th>\n",
       "      <th>Bsmt Unf SF</th>\n",
       "      <th>Total Bsmt SF</th>\n",
       "      <th>1st Flr SF</th>\n",
       "      <th>2nd Flr SF</th>\n",
       "      <th>Low Qual Fin SF</th>\n",
       "      <th>Gr Liv Area</th>\n",
       "      <th>Bsmt Full Bath</th>\n",
       "      <th>Bsmt Half Bath</th>\n",
       "      <th>Full Bath</th>\n",
       "      <th>Half Bath</th>\n",
       "      <th>Bedroom AbvGr</th>\n",
       "      <th>Kitchen AbvGr</th>\n",
       "      <th>TotRms AbvGrd</th>\n",
       "      <th>Fireplaces</th>\n",
       "      <th>Garage Cars</th>\n",
       "      <th>Garage Area</th>\n",
       "      <th>Wood Deck SF</th>\n",
       "      <th>Open Porch SF</th>\n",
       "      <th>Enclosed Porch</th>\n",
       "      <th>3Ssn Porch</th>\n",
       "      <th>Screen Porch</th>\n",
       "      <th>Pool Area</th>\n",
       "      <th>Misc Val</th>\n",
       "      <th>Yr Sold</th>\n",
       "      <th>SalePrice</th>\n",
       "      <th>Years Before Sale</th>\n",
       "      <th>Years Since Remod</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>31770</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>112.0</td>\n",
       "      <td>639.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>441.0</td>\n",
       "      <td>1080.0</td>\n",
       "      <td>1656</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1656</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>528.0</td>\n",
       "      <td>210</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>215000</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>11622</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>468.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>882.0</td>\n",
       "      <td>896</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>896</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>730.0</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>105000</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>14267</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>108.0</td>\n",
       "      <td>923.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>406.0</td>\n",
       "      <td>1329.0</td>\n",
       "      <td>1329</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1329</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>312.0</td>\n",
       "      <td>393</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12500</td>\n",
       "      <td>2010</td>\n",
       "      <td>172000</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>11160</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1065.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1045.0</td>\n",
       "      <td>2110.0</td>\n",
       "      <td>2110</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2110</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>522.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>244000</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>13830</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>791.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>928.0</td>\n",
       "      <td>928</td>\n",
       "      <td>701</td>\n",
       "      <td>0</td>\n",
       "      <td>1629</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>482.0</td>\n",
       "      <td>212</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>189900</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MS SubClass  Lot Area  Overall Qual  Overall Cond  Mas Vnr Area  \\\n",
       "0           20     31770             6             5         112.0   \n",
       "1           20     11622             5             6           0.0   \n",
       "2           20     14267             6             6         108.0   \n",
       "3           20     11160             7             5           0.0   \n",
       "4           60     13830             5             5           0.0   \n",
       "\n",
       "   BsmtFin SF 1  BsmtFin SF 2  Bsmt Unf SF  Total Bsmt SF  1st Flr SF  \\\n",
       "0         639.0           0.0        441.0         1080.0        1656   \n",
       "1         468.0         144.0        270.0          882.0         896   \n",
       "2         923.0           0.0        406.0         1329.0        1329   \n",
       "3        1065.0           0.0       1045.0         2110.0        2110   \n",
       "4         791.0           0.0        137.0          928.0         928   \n",
       "\n",
       "   2nd Flr SF  Low Qual Fin SF  Gr Liv Area  Bsmt Full Bath  Bsmt Half Bath  \\\n",
       "0           0                0         1656             1.0             0.0   \n",
       "1           0                0          896             0.0             0.0   \n",
       "2           0                0         1329             0.0             0.0   \n",
       "3           0                0         2110             1.0             0.0   \n",
       "4         701                0         1629             0.0             0.0   \n",
       "\n",
       "   Full Bath  Half Bath  Bedroom AbvGr  Kitchen AbvGr  TotRms AbvGrd  \\\n",
       "0          1          0              3              1              7   \n",
       "1          1          0              2              1              5   \n",
       "2          1          1              3              1              6   \n",
       "3          2          1              3              1              8   \n",
       "4          2          1              3              1              6   \n",
       "\n",
       "   Fireplaces  Garage Cars  Garage Area  Wood Deck SF  Open Porch SF  \\\n",
       "0           2          2.0        528.0           210             62   \n",
       "1           0          1.0        730.0           140              0   \n",
       "2           0          1.0        312.0           393             36   \n",
       "3           2          2.0        522.0             0              0   \n",
       "4           1          2.0        482.0           212             34   \n",
       "\n",
       "   Enclosed Porch  3Ssn Porch  Screen Porch  Pool Area  Misc Val  Yr Sold  \\\n",
       "0               0           0             0          0         0     2010   \n",
       "1               0           0           120          0         0     2010   \n",
       "2               0           0             0          0     12500     2010   \n",
       "3               0           0             0          0         0     2010   \n",
       "4               0           0             0          0         0     2010   \n",
       "\n",
       "   SalePrice  Years Before Sale  Years Since Remod  \n",
       "0     215000                 50                 50  \n",
       "1     105000                 49                 49  \n",
       "2     172000                 52                 52  \n",
       "3     244000                 42                 42  \n",
       "4     189900                 13                 12  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select numerical columns only\n",
    "numerical_df = transformed_df.select_dtypes(include=['int', 'float'])\n",
    "numerical_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BsmtFin SF 2         0.006127\n",
       "Misc Val             0.019273\n",
       "Yr Sold              0.030358\n",
       "3Ssn Porch           0.032268\n",
       "Bsmt Half Bath       0.035875\n",
       "Low Qual Fin SF      0.037629\n",
       "Pool Area            0.068438\n",
       "MS SubClass          0.085128\n",
       "Overall Cond         0.101540\n",
       "Screen Porch         0.112280\n",
       "Kitchen AbvGr        0.119760\n",
       "Enclosed Porch       0.128685\n",
       "Bedroom AbvGr        0.143916\n",
       "Bsmt Unf SF          0.182751\n",
       "Lot Area             0.267520\n",
       "2nd Flr SF           0.269601\n",
       "Bsmt Full Bath       0.276258\n",
       "Half Bath            0.284871\n",
       "Open Porch SF        0.316262\n",
       "Wood Deck SF         0.328183\n",
       "BsmtFin SF 1         0.439284\n",
       "Fireplaces           0.474831\n",
       "TotRms AbvGrd        0.498574\n",
       "Mas Vnr Area         0.506983\n",
       "Years Since Remod    0.534985\n",
       "Full Bath            0.546118\n",
       "Years Before Sale    0.558979\n",
       "1st Flr SF           0.635185\n",
       "Garage Area          0.641425\n",
       "Total Bsmt SF        0.644012\n",
       "Garage Cars          0.648361\n",
       "Gr Liv Area          0.717596\n",
       "Overall Qual         0.801206\n",
       "SalePrice            1.000000\n",
       "Name: SalePrice, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute absolute values of correlation coefficients between features and target column\n",
    "abs_corr_coeffs = numerical_df.corr()['SalePrice'].abs().sort_values()\n",
    "abs_corr_coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BsmtFin SF 1         0.439284\n",
       "Fireplaces           0.474831\n",
       "TotRms AbvGrd        0.498574\n",
       "Mas Vnr Area         0.506983\n",
       "Years Since Remod    0.534985\n",
       "Full Bath            0.546118\n",
       "Years Before Sale    0.558979\n",
       "1st Flr SF           0.635185\n",
       "Garage Area          0.641425\n",
       "Total Bsmt SF        0.644012\n",
       "Garage Cars          0.648361\n",
       "Gr Liv Area          0.717596\n",
       "Overall Qual         0.801206\n",
       "SalePrice            1.000000\n",
       "Name: SalePrice, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keep only columns with a correlation coefficient above 0.4\n",
    "abs_corr_coeffs[abs_corr_coeffs > 0.4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop columns with a correlation coefficient below 0.4\n",
    "transformed_df = transformed_df.drop(abs_corr_coeffs[abs_corr_coeffs < 0.4].index, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns that can be categorised as nominal variables are candidates for being converted to categorical. Let's check the [documentation](http://jse.amstat.org/v19n3/decock/DataDocumentation.txt) and look for nominal columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nominal columns to be converted to categorical \n",
    "nominal_features = [\"PID\", \"MS SubClass\", \"MS Zoning\", \"Street\", \"Alley\", \"Land Contour\", \"Lot Config\", \"Neighborhood\", \n",
    "                    \"Condition 1\", \"Condition 2\", \"Bldg Type\", \"House Style\", \"Roof Style\", \"Roof Matl\", \"Exterior 1st\", \n",
    "                    \"Exterior 2nd\", \"Mas Vnr Type\", \"Foundation\", \"Heating\", \"Central Air\", \"Garage Type\", \n",
    "                    \"Misc Feature\", \"Sale Type\", \"Sale Condition\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's find which columns are currently numerical but need to be encoded as categorical instead.\n",
    "\n",
    "We'll also check how many unique values we have in each categorical column and keep those features with up to 10 unique values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Numerical columns that need to be enconded as categorical\n",
    "transform_cat_cols = []\n",
    "for col in nominal_features:\n",
    "    if col in transformed_df.columns:\n",
    "        transform_cat_cols.append(col)\n",
    "        \n",
    "# Check how many unique values in each categorical column\n",
    "uniqueness_counts = transformed_df[transform_cat_cols].apply(lambda col: len(col.value_counts())).sort_values()\n",
    "\n",
    "# Keep categorical columns with up to 10 unique values\n",
    "drop_cols = uniqueness_counts[uniqueness_counts > 10].index\n",
    "transformed_df = transformed_df.drop(drop_cols, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's select just the remaining text columns, convert them to categorical columns, dummy code these columns and add them back to the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select text columns and convert to categorical\n",
    "text_cols = transformed_df.select_dtypes(include=['object'])\n",
    "for col in text_cols:\n",
    "    transformed_df[col] = transformed_df[col].astype('category')\n",
    "    \n",
    "# Create dummy columns and add them back to the data frame\n",
    "dummy_cols = pd.get_dummies(transformed_df.select_dtypes(include=['category']))\n",
    "transformed_df = pd.concat([transformed_df, dummy_cols], axis=1)\n",
    "\n",
    "# Drop the original text columns from the data frame\n",
    "transformed_df = transformed_df.drop(text_cols, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's update `select_features()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def select_features(df, coeff_threshold=0.4, uniq_threshold=10):\n",
    "    \n",
    "    # Select numerical columns only\n",
    "    # Compute absolute values of correlation coefficients between features and target column\n",
    "    # Drop columns with a correlation coefficient below 'coeff_threshold'\n",
    "    numerical_df = df.select_dtypes(include=['int', 'float'])\n",
    "    abs_corr_coeffs = numerical_df.corr()['SalePrice'].abs().sort_values()\n",
    "    df = df.drop(abs_corr_coeffs[abs_corr_coeffs < coeff_threshold].index, axis=1)\n",
    "    \n",
    "    # Nominal columns to be converted to categorical \n",
    "    nominal_features = [\"PID\", \"MS SubClass\", \"MS Zoning\", \"Street\", \"Alley\", \"Land Contour\", \"Lot Config\", \"Neighborhood\", \n",
    "                    \"Condition 1\", \"Condition 2\", \"Bldg Type\", \"House Style\", \"Roof Style\", \"Roof Matl\", \"Exterior 1st\", \n",
    "                    \"Exterior 2nd\", \"Mas Vnr Type\", \"Foundation\", \"Heating\", \"Central Air\", \"Garage Type\", \n",
    "                    \"Misc Feature\", \"Sale Type\", \"Sale Condition\"]\n",
    "    \n",
    "    # Numerical columns that need to be enconded as categorical\n",
    "    transform_cat_cols = []\n",
    "    for col in nominal_features:\n",
    "        if col in df.columns:\n",
    "            transform_cat_cols.append(col)\n",
    "        \n",
    "    # Check how many unique values in each categorical column\n",
    "    uniqueness_counts = df[transform_cat_cols].apply(lambda col: len(col.value_counts())).sort_values()\n",
    "\n",
    "    # Keep categorical columns with up to 'uniq_threshold' unique values\n",
    "    drop_cols = uniqueness_counts[uniqueness_counts > uniq_threshold].index\n",
    "    df = df.drop(drop_cols, axis=1)\n",
    "    \n",
    "    # Select text columns and convert to categorical\n",
    "    text_cols = df.select_dtypes(include=['object'])\n",
    "    for col in text_cols:\n",
    "        df[col] = df[col].astype('category')\n",
    "    \n",
    "    # Create dummy columns and add them back to the data frame\n",
    "    dummy_cols = pd.get_dummies(df.select_dtypes(include=['category']))\n",
    "    df = pd.concat([df, dummy_cols], axis=1)\n",
    "\n",
    "    # Drop the original text columns from the data frame\n",
    "    df = df.drop(text_cols, axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test\n",
    "\n",
    "Now for the final part of the pipeline, training and testing.\n",
    "\n",
    "Let's add a parameter named **`k`** that controls the type of cross-validation that occurs.\n",
    "\n",
    "- When **`k`** equals **`0`**, perform *holdout validation*.\n",
    "- When **`k`** equals **`1`**, perform *simple cross-validation*.\n",
    "- When **`k`** is greater than **`1`**, implement *k-fold cross-validation* using **`k`** folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_and_test(df, k=0):\n",
    "    numeric_df = df.select_dtypes(include=['int', 'float'])\n",
    "    features = numeric_df.columns.drop(\"SalePrice\")\n",
    "    target = 'SalePrice'\n",
    "    lr = LinearRegression()\n",
    "    \n",
    "    if k == 0:\n",
    "        train = df[0:1460]\n",
    "        test = df[1460:]\n",
    "\n",
    "        lr.fit(train[features], train[target])\n",
    "        predictions = lr.predict(test[features])\n",
    "        mse = mean_squared_error(test[target], predictions)\n",
    "        rmse = np.sqrt(mse)\n",
    "\n",
    "        return rmse\n",
    "    \n",
    "    if k == 1:\n",
    "        # Randomize all rows (frac=1) from 'df' and return it\n",
    "        shuffled_df = df.sample(frac=1)\n",
    "        train = df[0:1460]\n",
    "        test = df[1460:]\n",
    "        \n",
    "        lr.fit(train[features], train[target])\n",
    "        predictions_one = lr.predict(test[features])        \n",
    "        \n",
    "        mse_one = mean_squared_error(test[target], predictions_one)\n",
    "        rmse_one = np.sqrt(mse_one)\n",
    "        \n",
    "        lr.fit(test[features], test[target])\n",
    "        predictions_two = lr.predict(train[features])        \n",
    "       \n",
    "        mse_two = mean_squared_error(train[target], predictions_two)\n",
    "        rmse_two = np.sqrt(mse_two)\n",
    "        \n",
    "        avg_rmse = np.mean([rmse_one, rmse_two])\n",
    "        print(rmse_one)\n",
    "        print(rmse_two)\n",
    "        return avg_rmse\n",
    "    else:\n",
    "        kf = KFold(n_splits=k, shuffle=True)\n",
    "        rmse_values = []\n",
    "        for train_index, test_index, in kf.split(df):\n",
    "            train = df.iloc[train_index]\n",
    "            test = df.iloc[test_index]\n",
    "            lr.fit(train[features], train[\"SalePrice\"])\n",
    "            predictions = lr.predict(test[features])\n",
    "            mse = mean_squared_error(test[\"SalePrice\"], predictions)\n",
    "            rmse = np.sqrt(mse)\n",
    "            rmse_values.append(rmse)\n",
    "        print(rmse_values)\n",
    "        avg_rmse = np.mean(rmse_values)\n",
    "        return avg_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run our functions after all updates we've made using **`k`**=0, **`k`**=1 and **`k`**=4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36623.53562910476"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"AmesHousing.tsv\", delimiter=\"\\t\")\n",
    "\n",
    "# k=0\n",
    "transformed_df = transform_features(df)\n",
    "filtered_df = select_features(transformed_df)\n",
    "rmse = train_and_test(filtered_df, k=0)\n",
    "\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36623.53562910476\n",
      "30924.751476605\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "33774.143552854875"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# k=1\n",
    "transformed_df = transform_features(df)\n",
    "filtered_df = select_features(transformed_df)\n",
    "rmse = train_and_test(filtered_df, k=1)\n",
    "\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30953.58447600925, 40132.48026274354, 29296.56101502131, 31050.756002694994]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "32858.34543911727"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# k=4\n",
    "transformed_df = transform_features(df)\n",
    "filtered_df = select_features(transformed_df)\n",
    "rmse = train_and_test(filtered_df, k=4)\n",
    "\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this project, we used **Feature Engineering** and **Feature Selection** techniques to create and select the appropriate features for the Linear Regression Model. \n",
    "\n",
    "Then the model was evaluated using:\n",
    "- holdout validation\n",
    "- simple cross-validation\n",
    "- k-fold cross-validation\n",
    "\n",
    "The best result was obtained using *k-fold cross-validation* with **k** = 4."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
